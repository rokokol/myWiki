|          Назад | Дальше         |  Теги  | Оценка |                                          Трек-настрение                                          |
| --------------:|:-------------- |:------:|:------:|:------------------------------------------------------------------------------------------------:|
| [[2025-01-01]] | [[2025-01-03]] | #y2025 | #6f10  | [Ødyzon — sleepless (Super Slowed)](https://youtube.com/watch?v=fONi6j_pvWA&si=bt2ySAUhdBNyNsZ_) | 

# Атмосфера
> Впрочем, до чего я люблю зимнюю пору. Можно покататься на коньках, можно походить на лыжах. А дома... Ах, это чувство, когда за окном идет снег, а коленки твои согревает лежащий на них... *ноутбук*. Да, у программистов свои заботы и свои ценности

Сегодня, как обычно, поспал 12 часов, сходил на каток, повозмущался огромной очереди. Не знаю, нужно ли вдаваться в подробности — сдается мне, ничего интересного тут нет. *Куда более любопытно обстоятельство иное*

## Always 20, Always Sensless
> [!note] Я уже делился размышлениями о том, что хочу сделать текстовый квест на основе нейросетей
> Тем не менее я сегодня пробовал расчистить почву. Мне хотелось бы, чтобы не нужно было платить — то есть, чтобы разворачивалось все локально. И, даже если каким-то чудом сделать так, чтобы подобное решение стало доступно не программисту, есть другая проблема — *а какую модель использовать?*

 Таким образом я изучил [RWKV](https://www.rwkv.com/) — латентную RNN. Между тем, я так и не разобрался как запустить локально ее версию на 1B параметров
 И тут я от отчаяния полез в ютуб — быть может хотя бы квантованную *LLAMA*..? И тут я познакомился с [ollama](https://ollama.com). А потом и с [Qwen](https://huggingface.co/collections/Qwen/). И тут меня осенило — я, наконец-то, понял, как их развертывать *локально*. О боже, я обожаю *HuggingFace* с их *transformers* — насколько же это *исключительно удобно*

> [!summary] В конечном итоге
> Я почитал подробнее про квантизацию, о том, что это и как оно работает. Я научился развертывать модели локально. Я научился пользоваться *HuggingFace*. Узнал про *ollama*
> ...
> *К чему это все привело..?* — ~~Ну, ни к чему, грубо говоря)~~ Вообще, я понял, что локально развертывать мощностей никаких не хватит. Можно пробовать морочить голову с квантованными моделями, однако... *Зачем?*
> 
> Истина в том, что... Ну, это неразумно будет, в общем. Проще как для конечного пользователя, так и для меня будет изучить *LangChain* — штуку для работы с текстовыми моделями. И тем не менее, я узнал много нового и интересного за сегодня)